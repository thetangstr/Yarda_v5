# Gemini Image Generation Fix

**Date:** 2025-11-06
**Status:** ‚úÖ FIXED
**Branch:** 004-generation-flow

---

## Problem

The backend was unable to generate landscape images using Gemini AI. The code was using the wrong model and SDK:

### Issues Found

1. **Wrong Model**: Using `gemini-2.5-flash` (text-only model) instead of `gemini-2.5-flash-image` (image generation model)
2. **Wrong SDK**: Using old `google-generativeai` SDK instead of new `google-genai` SDK
3. **Wrong API Pattern**: Using `generate_content()` instead of `generate_content_stream()`
4. **Missing Configuration**: Missing `response_modalities=["IMAGE", "TEXT"]` and `image_config`
5. **Wrong Response Handling**: Trying to access `response.images` which doesn't exist

### Error Behavior

```python
# Old code (BROKEN):
self.model = genai.GenerativeModel("gemini-2.5-flash")  # ‚ùå Text model, no image generation
response = self.model.generate_content(...)
if hasattr(response, 'images') and response.images:  # ‚ùå Never exists
    return response.images[0].data
```

---

## Solution

Updated `backend/src/services/gemini_client.py` to use the correct Gemini 2.5 Flash Image model with streaming API.

### Changes Made

#### 1. Installed New SDK

```bash
pip install google-genai
```

#### 2. Updated Imports

```python
# OLD:
import google.generativeai as genai

# NEW:
from google import genai
from google.genai import types
import mimetypes
```

#### 3. Updated Client Initialization

```python
# OLD:
genai.configure(api_key=api_key)
self.model = genai.GenerativeModel("gemini-2.5-flash")

# NEW:
self.client = genai.Client(api_key=api_key)
self.model = "gemini-2.5-flash-image"  # Image generation model
```

#### 4. Updated Generation Method

```python
# Build content parts
content_parts = [
    types.Part.from_text(text=prompt)
]

# Add input image if provided
if input_image:
    content_parts.append(
        types.Part.from_bytes(
            data=input_image,
            mime_type="image/jpeg"
        )
    )

# Configure for image generation
generate_content_config = types.GenerateContentConfig(
    temperature=0.7,
    response_modalities=["IMAGE", "TEXT"],  # Enable image output
    image_config=types.ImageConfig(
        image_size="1K"  # 1024x1024 output
    )
)

# Use streaming API
image_data = None
text_response = ""

for chunk in self.client.models.generate_content_stream(
    model=self.model,
    contents=[
        types.Content(
            role="user",
            parts=content_parts
        )
    ],
    config=generate_content_config
):
    # Extract image from streaming chunks
    if (
        chunk.candidates is not None
        and chunk.candidates[0].content is not None
        and chunk.candidates[0].content.parts is not None
    ):
        for part in chunk.candidates[0].content.parts:
            # Extract inline image data
            if part.inline_data and part.inline_data.data:
                image_data = part.inline_data.data
                break
            # Also capture any text response
            elif hasattr(part, 'text') and part.text:
                text_response += part.text

# Verify image was generated
if not image_data:
    raise Exception("No image generated in Gemini response")

return image_data
```

---

## Testing

### Manual Test

To test the image generation:

```python
# backend/tests/manual_test_gemini.py
import asyncio
from src.services.gemini_client import GeminiClient

async def test_generation():
    client = GeminiClient()

    # Test text-to-image generation
    image_bytes = await client.generate_landscape_design(
        input_image=None,
        address="21125 Seven Springs Dr, Cupertino, CA 95014",
        area_type="backyard",
        style="modern_minimalist",
        custom_prompt="Add a modern patio with clean lines"
    )

    # Save result
    with open("/tmp/test_generation.png", "wb") as f:
        f.write(image_bytes)

    print("‚úÖ Image generated successfully!")
    print("üìÅ Saved to: /tmp/test_generation.png")

if __name__ == "__main__":
    asyncio.run(test_generation())
```

Run the test:

```bash
cd backend
./venv/bin/python tests/manual_test_gemini.py
```

### Expected Behavior

- ‚úÖ Image generates successfully
- ‚úÖ Output is 1024x1024 PNG
- ‚úÖ Image matches the style and prompt
- ‚úÖ No errors in console

---

## API Reference

### Gemini 2.5 Flash Image

- **Model ID**: `gemini-2.5-flash-image`
- **Input**: Text prompt + optional image
- **Output**: Generated image (inline_data in streaming chunks)
- **Image Size Options**: `"1K"` (1024x1024), `"2K"` (2048x2048)
- **Response Modalities**: Must include `"IMAGE"` in config

### Example Code (Simplified)

```python
from google import genai
from google.genai import types

client = genai.Client(api_key=api_key)

for chunk in client.models.generate_content_stream(
    model="gemini-2.5-flash-image",
    contents=[
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="Generate a modern backyard design")
            ]
        )
    ],
    config=types.GenerateContentConfig(
        response_modalities=["IMAGE", "TEXT"],
        image_config=types.ImageConfig(image_size="1K")
    )
):
    # Process streaming chunks
    for part in chunk.candidates[0].content.parts:
        if part.inline_data and part.inline_data.data:
            image_data = part.inline_data.data
```

---

## Files Modified

- `backend/src/services/gemini_client.py` - Updated to use gemini-2.5-flash-image model
- Backend restarted with new SDK

---

## Next Steps

1. ‚úÖ Backend restarted with updated code
2. ‚è≥ Test image generation with real Gemini API
3. ‚è≥ Update UI to match v2 design
4. ‚è≥ Fix webhook signature verification (separate issue)

---

## Related Issues

- **Webhook signature verification**: Still failing (unrelated to image generation)
- **UI doesn't match v2**: Needs design updates to GenerationProgress component

---

**Author:** Claude Code
**Reference:** Code example provided by user based on Google Gemini API documentation
